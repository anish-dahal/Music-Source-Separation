{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15e04fa9c70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_folder_path = \"../DSD100spectrogram/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_path = [spectrogram_folder_path + '/'+name for name in sorted(os.listdir(spectrogram_folder_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(spectrogram_path[0])\n",
    "mixture = data['mixture']\n",
    "bass = data['bass']\n",
    "drum = data['drum']\n",
    "vocal = data['vocal']\n",
    "instrumental = data['instrumental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSD100(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.spectrogram_path = [data_path + '/'+name for name in sorted(os.listdir(data_path))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spectrogram_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = np.load(self.spectrogram_path[index])\n",
    "        mixture = data['mixture'][np.newaxis,:511,:127]\n",
    "        bass = data['bass'][np.newaxis,:511,:127]\n",
    "        drum = data['drum'][np.newaxis,:511,:127]\n",
    "        vocal = data['vocal'][np.newaxis,:511,:127]\n",
    "        instrumental = data['instrumental'][np.newaxis,:511,:127]\n",
    "        return (\n",
    "            torch.from_numpy(np.copy(mixture)).to(device),\n",
    "            torch.from_numpy(np.copy(bass)).to(device),\n",
    "            torch.from_numpy(np.copy(drum)).to(device),\n",
    "            torch.from_numpy(np.copy(vocal)).to(device),\n",
    "            torch.from_numpy(np.copy(instrumental)).to(device)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DSD100('../DSD100spectrogram') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513, 128])\n",
      "torch.Size([1, 513, 128])\n",
      "torch.Size([1, 513, 128])\n",
      "torch.Size([1, 513, 128])\n",
      "torch.Size([1, 513, 128])\n"
     ]
    }
   ],
   "source": [
    "for mixture, bass, drum, vocal, instrumental in dataset:\n",
    "    print(mixture.shape)\n",
    "    print(bass.shape)\n",
    "    print(drum.shape)\n",
    "    print(vocal.shape)\n",
    "    print(instrumental.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7548"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(dataset, train_ratio):\n",
    "    return random_split(dataset, [train_ratio, 1 - train_ratio])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = data_split(dataset, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(dataset, batch_size = 64, shuffle = False):\n",
    "    return DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataloader(train_dataset, 128, shuffle = True)\n",
    "val_dataloader = dataloader(val_dataset, 128, shuffle = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for mixture, bass, drum, vocal, instrumental in train_dataloader:\n",
    "    print(mixture.shape)\n",
    "    print(bass.shape)\n",
    "    print(drum.shape)\n",
    "    print(vocal.shape)\n",
    "    print(instrumental.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use Data.py for making dataset, random_split and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomDataset.Data import (\n",
    "    DSD100,\n",
    "    data_split,\n",
    "    dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DSD100('../DSD100spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 511, 127])\n",
      "torch.Size([1, 511, 127])\n",
      "torch.Size([1, 511, 127])\n",
      "torch.Size([1, 511, 127])\n",
      "torch.Size([1, 511, 127])\n"
     ]
    }
   ],
   "source": [
    "for mixture, bass, drum, vocal, instrumental in dataset:\n",
    "    print(mixture.shape)\n",
    "    print(bass.shape)\n",
    "    print(drum.shape)\n",
    "    print(vocal.shape)\n",
    "    print(instrumental.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = data_split(dataset, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7199"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3085"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataloader(train_dataset, 128, shuffle = True)\n",
    "val_dataloader = dataloader(val_dataset, 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 511, 127])\n",
      "torch.Size([128, 1, 511, 127])\n",
      "torch.Size([128, 1, 511, 127])\n",
      "torch.Size([128, 1, 511, 127])\n",
      "torch.Size([128, 1, 511, 127])\n"
     ]
    }
   ],
   "source": [
    "for mixture, bass, drum, vocal, instrumental in train_dataloader:\n",
    "    print(mixture.shape)\n",
    "    print(bass.shape)\n",
    "    print(drum.shape)\n",
    "    print(vocal.shape)\n",
    "    print(instrumental.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
